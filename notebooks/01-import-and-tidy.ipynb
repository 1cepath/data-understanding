{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# Import and Tidy \n",
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 88,
        "hidden": false,
        "row": 5,
        "width": null
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "The purpose of this notebook is to import data from provided data sources and transform it into the Haystax's standard format. This involves cleaning, and tidying resulting in tidy data that has a consistent format and can be used for exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 97,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Set Environments\n",
    "Let's first install some packages (python and R) that we shall use for our analysis. We shall also set up our plotting requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('notebook', font_scale = 1.1)\n",
    "np.random.seed(12345)\n",
    "rc = {'xtick.labelsize': 40, 'ytick.labelsize': 40, 'axes.labelsize': 40, 'font.size': 40, 'lines.linewidth': 4.0, \n",
    "      'lines.markersize': 40, 'font.family': \"serif\", 'font.serif': \"cm\", 'savefig.dpi': 200,\n",
    "      'text.usetex': False, 'legend.fontsize': 40.0, 'axes.titlesize': 40, \"figure.figsize\": [24, 16]}\n",
    "sns.set(rc = rc)\n",
    "sns.set_style(\"darkgrid\")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 93,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Set Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 101,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Import data from the provided data sources such as:\n",
    "* Flat files e.g csv, json, text files\n",
    "* Databases e.g NoSQL (MongoDB), RDBMS (MS SQL)\n",
    "* Distributed File Systems e.g. Hadoop,\n",
    "* etc.\n",
    "\n",
    "The `pydata` stack provides several packages to read data these data sources. We shall implement these with each clients requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, specify data source here\n",
    "hard_disk = \"/opt/usb\"\n",
    "folder = \"cert/standardized\"\n",
    "file_type = \"*.parquet\" # may include csv, hdf, json, text, etc\n",
    "\n",
    "raw_data_email = os.path.join(hard_disk, \"cert/r6.2/email.csv\")\n",
    "raw_data_hr = os.path.join(hard_disk, \"cert/r6.2/hr.csv\")\n",
    "raw_data_print = os.path.join(hard_disk, \"cert/r6.2/print.csv\")\n",
    "raw_data_badge = os.path.join(hard_disk, \"cert/r6.2/badge.csv\")\n",
    "raw_data_network = os.path.join(hard_disk, \"cert/r6.2/logon.csv\")\n",
    "raw_data_usb = os.path.join(hard_disk, \"cert/r6.2/device.csv\")\n",
    "\n",
    "working_dir = os.path.join(hard_disk, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Data\n",
    "-----\n",
    "### Import Raw Email Data\n",
    "If the data is a flat file, let's read in the data using `dask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 107,
        "width": 12
       },
       "report_default": {}
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for csv files\n",
    "ddf = dd.read_csv(raw_data_email, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy the Email Data\n",
    "Let's clean the data and tidy it into a constient semantic.  \n",
    "Let's view the first three records and the structure of the resulting `pandas` dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>pc</th>\n",
       "      <th>to</th>\n",
       "      <th>cc</th>\n",
       "      <th>bcc</th>\n",
       "      <th>from</th>\n",
       "      <th>activity</th>\n",
       "      <th>size</th>\n",
       "      <th>attachments</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{I1O2-B4EB49RW-7379WSQW}</td>\n",
       "      <td>2010-01-02 06:36:41</td>\n",
       "      <td>HDB1666</td>\n",
       "      <td>PC-6793</td>\n",
       "      <td>Louis.Bernard.Garza@dtaa.com</td>\n",
       "      <td>Emery.Ali.Holloway@dtaa.com</td>\n",
       "      <td>Hector.Donovan.Bray@dtaa.com</td>\n",
       "      <td>Hector.Donovan.Bray@dtaa.com</td>\n",
       "      <td>Send</td>\n",
       "      <td>45659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now Sylvia, the object of Aminta's desire, arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{L7E7-V4UX89RR-3036ZDHU}</td>\n",
       "      <td>2010-01-02 06:40:02</td>\n",
       "      <td>HDB1666</td>\n",
       "      <td>PC-6793</td>\n",
       "      <td>Hector.Donovan.Bray@dtaa.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luke.Grant.Mcmahon@dtaa.com</td>\n",
       "      <td>View</td>\n",
       "      <td>34142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On May 14, they picked up 44 more Iroquois at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{S8C2-Q8YX87DJ-0516SIWZ}</td>\n",
       "      <td>2010-01-02 06:42:48</td>\n",
       "      <td>HDB1666</td>\n",
       "      <td>PC-6793</td>\n",
       "      <td>Quintessa.O.Farrell@harris.com</td>\n",
       "      <td>Hector.Donovan.Bray@dtaa.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hector.Donovan.Bray@dtaa.com</td>\n",
       "      <td>Send</td>\n",
       "      <td>1310925</td>\n",
       "      <td>C:\\28X79b6\\0PAGXTJ8.doc(1119253);C:\\11b38g6\\5M...</td>\n",
       "      <td>Sylvia is notable for its mythological Arcadia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                date     user       pc  \\\n",
       "0  {I1O2-B4EB49RW-7379WSQW} 2010-01-02 06:36:41  HDB1666  PC-6793   \n",
       "1  {L7E7-V4UX89RR-3036ZDHU} 2010-01-02 06:40:02  HDB1666  PC-6793   \n",
       "2  {S8C2-Q8YX87DJ-0516SIWZ} 2010-01-02 06:42:48  HDB1666  PC-6793   \n",
       "\n",
       "                               to                            cc  \\\n",
       "0    Louis.Bernard.Garza@dtaa.com   Emery.Ali.Holloway@dtaa.com   \n",
       "1    Hector.Donovan.Bray@dtaa.com                           NaN   \n",
       "2  Quintessa.O.Farrell@harris.com  Hector.Donovan.Bray@dtaa.com   \n",
       "\n",
       "                            bcc                          from activity  \\\n",
       "0  Hector.Donovan.Bray@dtaa.com  Hector.Donovan.Bray@dtaa.com     Send   \n",
       "1                           NaN   Luke.Grant.Mcmahon@dtaa.com     View   \n",
       "2                           NaN  Hector.Donovan.Bray@dtaa.com     Send   \n",
       "\n",
       "      size                                        attachments  \\\n",
       "0    45659                                                NaN   \n",
       "1    34142                                                NaN   \n",
       "2  1310925  C:\\28X79b6\\0PAGXTJ8.doc(1119253);C:\\11b38g6\\5M...   \n",
       "\n",
       "                                             content  \n",
       "0  Now Sylvia, the object of Aminta's desire, arr...  \n",
       "1  On May 14, they picked up 44 more Iroquois at ...  \n",
       "2  Sylvia is notable for its mythological Arcadia...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ddf.head(n = 3)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 93,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Our `pandas` dataframe comprises columns that we are interested in such as \"user\" (username), \"date\", \"to\" (the recipient email address) and \"size\" (attachment size) of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 12 columns):\n",
      "id             3 non-null object\n",
      "date           3 non-null datetime64[ns]\n",
      "user           3 non-null object\n",
      "pc             3 non-null object\n",
      "to             3 non-null object\n",
      "cc             2 non-null object\n",
      "bcc            1 non-null object\n",
      "from           3 non-null object\n",
      "activity       3 non-null object\n",
      "size           3 non-null int64\n",
      "attachments    1 non-null object\n",
      "content        3 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(10)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns_email(ddf, working_dir):\n",
    "    \n",
    "    required_columns = [\"record_id\", \"sender_employee_id\", \"sender_username\", \n",
    "                        \"subject\", \"timestamp\", \"number_of_attachments\", \n",
    "                        \"attachment_size\", \"email_text\", \"file_date\"]\n",
    "\n",
    "    ddf = ddf.rename(columns = {\"id\" : \"record_id\",\n",
    "                        \"user\" : \"sender_employee_id\",\n",
    "                        \"from\" : \"sender_username\",\n",
    "                        \"date\" : \"timestamp\",\n",
    "                         \"attachments\" : \"number_of_attachments\",\n",
    "                        \"size\" : \"attachment_size\", \n",
    "                        \"content\": \"email_text\"\n",
    "                        })\n",
    "\n",
    "    ddf[\"subject\"] = \"\"\n",
    "    ddf[\"file_date\"] = \"\"\n",
    "    ddf = ddf[required_columns]\n",
    "    \n",
    "    ddf[[\"subject\", \"email_text\"]] = ddf[[\"subject\", \"email_text\"]].astype('str')\n",
    "    ddf[\"number_of_attachments\"] = ddf[\"number_of_attachments\"].astype('int64')\n",
    "    ddf[\"attachment_size\"] = ddf[\"attachment_size\"].astype('float64')\n",
    "    ddf = ddf.categorize(columns = [\"record_id\", \"sender_employee_id\", \"sender_username\"])\n",
    "#     ddf[[\"record_id\", \"sender_employee_id\", \n",
    "#          \"sender_username\"]] = ddf[[\"record_id\", \"sender_employee_id\", \n",
    "#                                     \"sender_username\"]].astype('category')\n",
    "    \n",
    "    # save the standardized data as a distributed parquet file\n",
    "    ddf.to_parquet(path = working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize_columns_email(ddf = ddf, working_dir = working_dir+\"/email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 9 columns):\n",
      "record_id                1 non-null object\n",
      "sender_employee_id       1 non-null object\n",
      "sender_username          1 non-null object\n",
      "subject                  1 non-null object\n",
      "timestamp                1 non-null datetime64[ns]\n",
      "number_of_attachments    0 non-null object\n",
      "attachment_size          1 non-null int64\n",
      "email_text               1 non-null object\n",
      "file_date                1 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(7)\n",
      "memory usage: 152.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dd.read_parquet(working_dir+\"/email/*.parquet\").head(n = 1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USB Data\n",
    "----\n",
    "### Import USB Data\n",
    "USB data is provided by the `device.csv` file in CERT.  \n",
    "`device.csv` shows the connection and disconnet status of each employee that plugged in a USB. \n",
    "\n",
    "Users are assigned a normal/average number of thumb drive uses per day. Deviations from a user's normal usage can be considered significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for csv files\n",
    "ddf = dd.read_csv(raw_data_usb, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy the USB Data\n",
    "Let's clean the data and tidy it into a constient semantic.  \n",
    "Let's view the first three records and the structure of the resulting `pandas` dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>pc</th>\n",
       "      <th>file_tree</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{Z2Q8-K3AV28BE-9353JIRT}</td>\n",
       "      <td>2010-01-02 07:17:18</td>\n",
       "      <td>SDH2394</td>\n",
       "      <td>PC-5849</td>\n",
       "      <td>R:\\;R:\\22B5gX4;R:\\SDH2394</td>\n",
       "      <td>Connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{C7F1-G7LE60RU-2483DAXS}</td>\n",
       "      <td>2010-01-02 07:22:42</td>\n",
       "      <td>JKS2444</td>\n",
       "      <td>PC-6961</td>\n",
       "      <td>R:\\;R:\\JKS2444</td>\n",
       "      <td>Connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{T9A4-D4RV69OF-1704NINW}</td>\n",
       "      <td>2010-01-02 07:31:42</td>\n",
       "      <td>CBA1023</td>\n",
       "      <td>PC-1570</td>\n",
       "      <td>R:\\;R:\\42gY283;R:\\48rr4y2;R:\\59ntt61;R:\\76xCQG...</td>\n",
       "      <td>Connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                date     user       pc  \\\n",
       "0  {Z2Q8-K3AV28BE-9353JIRT} 2010-01-02 07:17:18  SDH2394  PC-5849   \n",
       "1  {C7F1-G7LE60RU-2483DAXS} 2010-01-02 07:22:42  JKS2444  PC-6961   \n",
       "2  {T9A4-D4RV69OF-1704NINW} 2010-01-02 07:31:42  CBA1023  PC-1570   \n",
       "\n",
       "                                           file_tree activity  \n",
       "0                          R:\\;R:\\22B5gX4;R:\\SDH2394  Connect  \n",
       "1                                     R:\\;R:\\JKS2444  Connect  \n",
       "2  R:\\;R:\\42gY283;R:\\48rr4y2;R:\\59ntt61;R:\\76xCQG...  Connect  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ddf.head(n = 3)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "Our `pandas` dataframe comprises columns that we are interested in such as \"user\" (username), \"date\", \"to\" (the recipient email address) and \"size\" (attachment size) of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 6 columns):\n",
      "id           3 non-null object\n",
      "date         3 non-null datetime64[ns]\n",
      "user         3 non-null object\n",
      "pc           3 non-null object\n",
      "file_tree    3 non-null object\n",
      "activity     3 non-null object\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns_usb(ddf, working_dir):\n",
    "    \n",
    "    required_columns = [\"record_id\", \"employee_id\", \"timestamp\", \"computer_id\", \n",
    "                        \"file_tree\", \"connect_activity\"]\n",
    "\n",
    "    ddf = ddf.rename(columns = {\"id\" : \"record_id\",\n",
    "                        \"user\" : \"employee_id\",\n",
    "                        \"date\" : \"timestamp\",\n",
    "                         \"pc\" : \"computer_id\", \n",
    "                        \"activity\": \"connect_activity\"\n",
    "                        })\n",
    "\n",
    "    ddf = ddf[required_columns]\n",
    "    \n",
    "    ddf[\"file_tree\"] = ddf[\"file_tree\"].astype('str')\n",
    "    ddf = ddf.categorize(columns = [\"record_id\", \"employee_id\", \n",
    "                                    \"computer_id\", \"connect_activity\"])\n",
    "#     ddf[[\"record_id\", \"employee_id\", \"computer_id\" \n",
    "#          \"connect_activity\"]] = ddf[[\"record_id\", \"employee_id\", \"computer_id\", \n",
    "#                                     \"connect_activity\"]].astype('category')\n",
    "    \n",
    "    # save the standardized data as a distributed parquet file\n",
    "    ddf.to_parquet(path = working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize_columns_usb(ddf, working_dir+\"/usb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the final data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      "record_id           1 non-null object\n",
      "employee_id         1 non-null object\n",
      "timestamp           1 non-null datetime64[ns]\n",
      "computer_id         1 non-null object\n",
      "file_tree           1 non-null object\n",
      "connect_activity    1 non-null object\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 128.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dd.read_parquet(working_dir+\"/usb/*.parquet\").head(n = 1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Data\n",
    "### Import Raw Print Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for csv files\n",
    "ddf = dd.read_csv(raw_data_print, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Data\n",
    "----\n",
    "### Import Raw Network Data\n",
    "Network data is provided by the `logon.csv` file in CERT.  \n",
    "`logon.csv` shows logon/logoff activity status of employees to the company network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for csv files\n",
    "ddf = dd.read_csv(raw_data_network, parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 209,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# Final thoughts\n",
    "\n",
    "This study proposed a Bayesian nonparametric framework to capture implicitly hidden structure in time-series having limited data. The proposed framework, a Gaussian process with a spectral mixture kernel, was applied to time-series process for insider-threat data. The proposed framework addresses two current challenges when analyzing quite noisy time-series having limited data whereby the time series are visualized for noticeable structure such as periodicity, growing or decreasing trends and hard coding them into pre-specified functional forms. Experiments demonstrated that results from this framework outperform traditional ARIMA when the time series does not have easily noticeable structure and is quite noisy. Future work will involve evaluating the proposed framework on other different types of insider-threat behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 174,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# Computing Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following computing environment was used to generate the above analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 13,
        "hidden": false,
        "row": 175,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# print system information/setup\n",
    "%reload_ext watermark\n",
    "%watermark -v -m -p numpy,pandas,matplotlib,ipywidgets,seaborn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
